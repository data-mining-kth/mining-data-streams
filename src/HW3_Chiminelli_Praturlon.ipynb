{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOIaEvWVUKFp"
   },
   "source": [
    "# ID2222 Data Mining, Homework 3\n",
    "# **Mining Data Streams**\n",
    "\n",
    "Brando Chiminelli, Tommaso Praturlon\n",
    "\n",
    "November 28th, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PqOxlll3C1p"
   },
   "source": [
    "## Goal\n",
    "The goal of this notebook is to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35iKgnWG3C1q"
   },
   "source": [
    "## How to run\n",
    "\n",
    "In order to run this notebook you need to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GM40ygli7Q3"
   },
   "source": [
    "## Import libraries and read the dataset\n",
    "In the following we import the few libraries needed for the project and we read the dataset.\n",
    "\n",
    "We decided to read the first 2000 baskets from the dataset in order to reduce weight on memory. Our assumption is that items are uniformly distributed across the dataset, thus allowing us to have a good insight only from the given sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1669145043831,
     "user": {
      "displayName": "Tommaso Praturlon",
      "userId": "14876307488286215212"
     },
     "user_tz": -60
    },
    "id": "zQlgKVYLlywG",
    "outputId": "df8fe523-9172-4ca3-abcf-8a2f83d92af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read successfully!\n",
      "     0\n",
      "0  0 1\n",
      "1  0 2\n",
      "2  0 3\n",
      "3  0 4\n",
      "4  0 5\n",
      "Number of rows:  88234\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "PATH_TO_DATA = \"../data/facebook_combined.txt\"\n",
    "df_graphs = pd.read_csv(PATH_TO_DATA, header=None)\n",
    "print(\"Data read successfully!\")\n",
    "\n",
    "# Reduce dataset size for computation overload (temporary)\n",
    "#df_graphs = df_graphs.iloc[0:25000]\n",
    "print(df_graphs.head())\n",
    "print(\"Number of rows: \", len(df_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA WRANGLING\n",
    "# 1. remove text rows from dataset\n",
    "# 2. create a dataset of integers\n",
    "data = []\n",
    "for i in range(len(df_graphs)):\n",
    "    s = [int(x) for x in str(df_graphs.iloc[i][0]).split(' ')]\n",
    "    #s = str(df_g.iloc[i][0]).split('\\t')\n",
    "    data.append(s)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA WRANGLING\n",
    "# 1. remove text rows from dataset\n",
    "# 2. create a dataset of integers\n",
    "#df_g = df_graphs.drop([0, 1, 2, 3, 4])\n",
    "#data = []\n",
    "#for i in range(len(df_g)):\n",
    "#    s = [int(x) for x in str(df_g.iloc[i][0]).split('\\t')]\n",
    "    #s = str(df_g.iloc[i][0]).split('\\t')\n",
    "#    data.append(s)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# TRIEST-BASE CLASS IMPLEMENTATION #\n",
    "####################################\n",
    "\n",
    "class TriestBase:\n",
    "    '''\n",
    "    Implementation of the Tri√®st-base algorithm\n",
    "    - function SampleEdge\n",
    "    - function UpdateCounter\n",
    "    - function FlipBiasedCoin\n",
    "    '''\n",
    "    def __init__(self, M = 100):\n",
    "        self.M = M\n",
    "        self.S = []\n",
    "        self.tau = 0\n",
    "        self.tau_loc = {}\n",
    "        self.t = 0\n",
    "    \n",
    "    def flipBiasedCoin(self, t):\n",
    "        '''\n",
    "        Flip a biased coin with probability M/t of falling head.\n",
    "        '''\n",
    "        # 1: head, 0: tail\n",
    "        result = np.random.choice([1, 0], p=[self.M/t, (1-self.M/t)])\n",
    "        if result:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def sampleEdge(self, t):\n",
    "        '''\n",
    "        Receives the edge (u,v) as [u, v] and time t at which\n",
    "        the stream element is received. t is a count integer.\n",
    "        Returns a boolean\n",
    "        '''\n",
    "        if (t <= self.M):\n",
    "            return True\n",
    "        elif self.flipBiasedCoin(t):\n",
    "            # select random edge from S\n",
    "            random_edge = random.choice(self.S)\n",
    "            # Delete random_edge from S\n",
    "            self.S.remove(random_edge)\n",
    "            # Update counters\n",
    "            self.updateCounters('delete', random_edge)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    def updateCounters(self, operation, edge):\n",
    "        '''\n",
    "        Receives the operation insertion or deletion\n",
    "        and the edge.\n",
    "        tau is the global counter\n",
    "        e.g S = [[5,10], [10, 3], [12, 5], [12, 3]]\n",
    "        edge = (5, 12)\n",
    "        N_5 = (10, 12)\n",
    "        N_12 = (5, 3)\n",
    "        N_5_12 = (5, 12)\n",
    "        '''\n",
    "        # Define shared-neighborhood\n",
    "        shared_neigh = set()\n",
    "        neigh_u = set() # all neighbors of edge[0]\n",
    "        neigh_v = set() # all nneighbors of edge[1]\n",
    "        #print(\"S from updateCounters():\\n\", S)\n",
    "        for elem in self.S:\n",
    "            # check that for the v in V_t (u,v) belongs to S\n",
    "            # create neigh_u\n",
    "            if edge[0] == elem[0]: # found u in position 0\n",
    "                neigh_u.add(edge[1]) # add the other element\n",
    "            if edge[0] == elem[1]: # found u in position 1\n",
    "                neigh_u.add(edge[0]) # add the other element\n",
    "            # create neigh_v\n",
    "            if edge[1] == elem[0]: # found v in position 0\n",
    "                neigh_v.add(edge[1]) \n",
    "            if edge[1] == elem[1]: # found v in position 1\n",
    "                neigh_v.add(edge[0])\n",
    "        # shared neighbourhood is the intersection between the sets\n",
    "        shared_neigh = neigh_u.intersection(neigh_v)\n",
    "        shared_neigh = set.intersection(neigh_u, neigh_v)\n",
    "\n",
    "        for c in shared_neigh:    \n",
    "            if operation == 'insert':\n",
    "                # Insert\n",
    "                self.tau += 1\n",
    "                self.tau_loc[c] = self.tau_loc.get(c, 0) + 1\n",
    "                self.tau_loc[edge[0]] = self.tau_loc.get(edge[0], 0) + 1\n",
    "                self.tau_loc[edge[1]] = self.tau_loc.get(edge[1], 0) + 1\n",
    "            \n",
    "            else:\n",
    "                # Delete\n",
    "                    self.tau -= 1\n",
    "                    self.tau_loc[c] = self.tau_loc.get(c, 0) - 1\n",
    "                    if self.tau_loc[c] <= 0:\n",
    "                        del self.tau_loc[c]\n",
    "                    self.tau_loc[edge[0]] = self.tau_loc.get(edge[0], 0) - 1\n",
    "                    if self.tau_loc[edge[0]] <= 0:\n",
    "                        del self.tau_loc[edge[0]]\n",
    "                    self.tau_loc[edge[1]] = self.tau_loc.get(edge[1], 0) - 1\n",
    "                    if self.tau_loc[edge[1]] <= 0:\n",
    "                        del self.tau_loc[edge[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges:  88234\n",
      "Eps:  10740.85743886422\n",
      "Estimated triangles:  3662632.3866526987\n",
      "341\n"
     ]
    }
   ],
   "source": [
    "# EXPLOITING THE CLASS TRIEST-BASE\n",
    "\n",
    "'''\n",
    "At time _t\n",
    "Graph G_t = (set of verteces V_t, set of edges E_t) \n",
    "'''\n",
    "tb = TriestBase(4000)\n",
    "\n",
    "print(\"Number of edges: \", len(data))\n",
    "# simulate the stream of data\n",
    "for  i in range(len(data)):\n",
    "    tb.t += 1\n",
    "    element = data[i]\n",
    "    #print(edge)\n",
    "    if tb.sampleEdge(tb.t):\n",
    "        tb.S.append(element)\n",
    "        tb.updateCounters('insert', element)\n",
    "        \n",
    "eps = max(1, (tb.t*(tb.t-1)*(tb.t-2))/(tb.M*(tb.M-1)*(tb.M-2)))\n",
    "est_triangles = eps*tb.tau\n",
    "print(\"Eps: \", eps)\n",
    "print(\"Estimated triangles: \", est_triangles)\n",
    "print(tb.tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1669145064318,
     "user": {
      "displayName": "Tommaso Praturlon",
      "userId": "14876307488286215212"
     },
     "user_tz": -60
    },
    "id": "S2F_AwI2i7Q_",
    "outputId": "bdcf0770-93b3-485e-fbfb-a78673035ee4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncnt = Counter(C_1.values())\\nplt.bar(cnt.keys(), cnt.values())\\n\\nplt.xlabel('Frequency')\\nplt.ylabel('Number of documents with that frequency')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Graphs and statistics \n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "'''\n",
    "cnt = Counter(C_1.values())\n",
    "plt.bar(cnt.keys(), cnt.values())\n",
    "\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Number of documents with that frequency')\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
