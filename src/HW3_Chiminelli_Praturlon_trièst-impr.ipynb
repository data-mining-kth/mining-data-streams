{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOIaEvWVUKFp"
   },
   "source": [
    "# ID2222 Data Mining, Homework 3\n",
    "# **Mining Data Streams**\n",
    "\n",
    "Brando Chiminelli, Tommaso Praturlon\n",
    "\n",
    "November 28th, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PqOxlll3C1p"
   },
   "source": [
    "## Goal\n",
    "The goal of this notebook is to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PqOxlll3C1p"
   },
   "source": [
    "The improved version is based on the base version of TRIEST. The changes are:\n",
    "\n",
    "1. UpdateCounters is called unconditionally for each element on the stream, before the algorithm decides whether or not to insert the edge into S.\n",
    "2. TRIEST-impr never decrements the counters when an edge is removed from S.\n",
    "3. UpdateCounters performs a weighted increase of the counters using η(t) = max{1,(t − 1)(t − 2)/(M(M − 1))} as weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GM40ygli7Q3"
   },
   "source": [
    "## Import libraries and read the dataset\n",
    "In the following we import the few libraries needed for the project and we read the dataset.\n",
    "\n",
    "We decided to read the first 2000 baskets from the dataset in order to reduce weight on memory. Our assumption is that items are uniformly distributed across the dataset, thus allowing us to have a good insight only from the given sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1669145043831,
     "user": {
      "displayName": "Tommaso Praturlon",
      "userId": "14876307488286215212"
     },
     "user_tz": -60
    },
    "id": "zQlgKVYLlywG",
    "outputId": "df8fe523-9172-4ca3-abcf-8a2f83d92af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read successfully!\n",
      "                                                   0\n",
      "0  # Directed graph (each unordered pair of nodes...\n",
      "1                     # Stanford web graph from 2002\n",
      "2                     # Nodes: 281903 Edges: 2312497\n",
      "3                             # FromNodeId\\tToNodeId\n",
      "4                                            1\\t6548\n",
      "Number of rows:  50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "PATH_TO_DATA = \"../data/web-Stanford.txt\"\n",
    "df_graphs = pd.read_csv(PATH_TO_DATA, header=None)\n",
    "print(\"Data read successfully!\")\n",
    "\n",
    "# Reduce dataset size for computation overload (temporary)\n",
    "df_graphs = df_graphs.iloc[0:50]\n",
    "print(df_graphs.head())\n",
    "print(\"Number of rows: \", len(df_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 15409], [6548, 57031], [15409, 13102], [2, 17794], [2, 25202], [2, 53625], [2, 54582], [2, 64930], [2, 73764], [2, 84477], [2, 98628], [2, 100193], [2, 102355], [2, 105318], [2, 105730], [2, 115926], [2, 140864], [2, 163550], [2, 164599], [2, 175799], [2, 178642], [2, 181714], [2, 190453], [2, 204189], [2, 204604], [2, 210870], [2, 213966], [2, 225119], [2, 241596], [2, 243294], [2, 246897], [2, 251658], [2, 252915], [2, 280935], [252915, 2], [246897, 2], [246897, 78056], [251658, 2], [280935, 2], [213966, 2], [213966, 47149], [243294, 2], [225119, 2], [241596, 2], [178642, 2]]\n"
     ]
    }
   ],
   "source": [
    "# DATA WRANGLING\n",
    "# 1. remove text rows from dataset\n",
    "# 2. create a dataset of integers\n",
    "df_g = df_graphs.drop([0, 1, 2, 3, 4])\n",
    "data = []\n",
    "for i in range(len(df_g)):\n",
    "    s = [int(x) for x in str(df_g.iloc[i][0]).split('\\t')]\n",
    "    #s = str(df_g.iloc[i][0]).split('\\t')\n",
    "    data.append(s)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# TRIEST-BASE CLASS IMPLEMENTATION #\n",
    "####################################\n",
    "\n",
    "class TriestBase:\n",
    "    '''\n",
    "    Implementation of the Trièst-base algorithm\n",
    "    - function SampleEdge\n",
    "    - function UpdateCounter\n",
    "    - function FlipBiasedCoin\n",
    "    '''\n",
    "        \n",
    "    def flipBiasedCoin(self, M, t):\n",
    "        '''\n",
    "        Flip a biased coin with probability M/t of falling head.\n",
    "        '''\n",
    "        import numpy as np\n",
    "        # 1: head, 0: tail\n",
    "        result = np.random.choice([1, 0], p=[M/t, (1-M/t)])\n",
    "        if result:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def sampleEdge(self, edge, t, S, M, tau, tau_loc):\n",
    "        '''\n",
    "        Receives the edge (u,v) as [u, v] and time t at which\n",
    "        the stream element is received. t is a count integer.\n",
    "        Returns a boolean\n",
    "        '''\n",
    "        import random\n",
    "        \n",
    "        if (t <= M):\n",
    "            return True\n",
    "        elif self.flipBiasedCoin(M, t):\n",
    "            # select random edge from S\n",
    "            random_edge = random.choice(S)\n",
    "            # Delete random_edge from S\n",
    "            S.remove(random_edge)\n",
    "            # IMPR: remove the call to function update_counters\n",
    "            #self.updateCounters('delete', random_edge, S, tau, tau_loc)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    def updateCounters(self, operation, t, edge, S, M, tau, tau_loc):\n",
    "        '''\n",
    "        Receives the operation insertion or deletion\n",
    "        and the edge.\n",
    "        tau is the global counter\n",
    "        e.g S = [[5,10], [10, 3], [12, 5], [12, 3]]\n",
    "        edge = (5, 12)\n",
    "        N_5 = (10, 12)\n",
    "        N_12 = (5, 3)\n",
    "        N_5_12 = (5, 12)\n",
    "        '''\n",
    "\n",
    "        # trièst-impr never decrements the counters when an edge is removed from S\n",
    "        # operation only 'insert'\n",
    "        # UpdateCounters performs a weighted increase of the counters\n",
    "\n",
    "        # Define shared-neighborhood\n",
    "        shared_neigh = set()\n",
    "        neigh_u = set() # all neighbors of edge[0]\n",
    "        neigh_v = set() # all nneighbors of edge[1]\n",
    "        #print(\"S from updateCounters():\\n\", S)\n",
    "        for elem in S:\n",
    "            # check that for the v in V_t (u,v) belongs to S\n",
    "            # create neigh_u\n",
    "            if edge[0] == elem[0]: # found u in position 0\n",
    "                neigh_u.add(edge[1]) # add the other element\n",
    "            if edge[0] == elem[1]: # found u in position 1\n",
    "                neigh_u.add(edge[0]) # add the other element\n",
    "            # create neigh_v\n",
    "            if edge[1] == elem[0]: # found v in position 0\n",
    "                neigh_v.add(edge[1]) \n",
    "            if edge[1] == elem[1]: # found v in position 1\n",
    "                neigh_v.add(edge[0])\n",
    "        # shared neighbourhood is the intersection between the sets\n",
    "        #shared_neigh = neigh_u.intersection(neigh_v)\n",
    "        shared_neigh = set.intersection(neigh_u, neigh_v)\n",
    "\n",
    "        weight = max(1, (((t-1)*(t-2))/(M*(M-1))))\n",
    "\n",
    "        for c in shared_neigh:\n",
    "                tau += weight\n",
    "                tau_loc[c] = tau_loc.get(c, 0) + weight\n",
    "                tau_loc[edge[0]] = tau_loc.get(edge[0], 0) + weight\n",
    "                tau_loc[edge[1]] = tau_loc.get(edge[1], 0) + weight\n",
    "\n",
    "        \n",
    "        return tau, tau_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges:  2312496\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[39mif\u001b[39;00m TriestBase()\u001b[39m.\u001b[39msampleEdge(edge, t, S, M, tau, tau_loc):\n\u001b[1;32m     21\u001b[0m         S\u001b[39m.\u001b[39mappend(edge)\n\u001b[0;32m---> 23\u001b[0m     tau, tau_loc \u001b[39m=\u001b[39m TriestBase()\u001b[39m.\u001b[39;49mupdateCounters(\u001b[39m'\u001b[39;49m\u001b[39minsert\u001b[39;49m\u001b[39m'\u001b[39;49m, t, edge, S, M, tau, tau_loc)\n\u001b[1;32m     26\u001b[0m \u001b[39m# Epsilon\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(t)\n",
      "Cell \u001b[0;32mIn [15], line 75\u001b[0m, in \u001b[0;36mTriestBase.updateCounters\u001b[0;34m(self, operation, t, edge, S, M, tau, tau_loc)\u001b[0m\n\u001b[1;32m     73\u001b[0m     neigh_u\u001b[39m.\u001b[39madd(edge[\u001b[39m0\u001b[39m]) \u001b[39m# add the other element\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m# create neigh_v\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m \u001b[39mif\u001b[39;00m edge[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m elem[\u001b[39m0\u001b[39;49m]: \u001b[39m# found v in position 0\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     neigh_v\u001b[39m.\u001b[39madd(edge[\u001b[39m1\u001b[39m]) \n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m edge[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m elem[\u001b[39m1\u001b[39m]: \u001b[39m# found v in position 1\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# EXPLOITING THE CLASS TRIEST-BASE\n",
    "\n",
    "'''\n",
    "At time _t\n",
    "Graph G_t = (set of verteces V_t, set of edges E_t) \n",
    "'''\n",
    "\n",
    "S = []\n",
    "M = 3000\n",
    "t = 0\n",
    "tau = 0\n",
    "tau_loc = {} # dictionary of local counts (u: counts) {5: 99, 12: 3, 2:1}\n",
    "\n",
    "print(\"Number of edges: \", len(data))\n",
    "# simulate the stream of data\n",
    "for i in range(len(data)):\n",
    "    t += 1\n",
    "    edge = data[i]\n",
    "    #print(edge)\n",
    "    if TriestBase().sampleEdge(edge, t, S, M, tau, tau_loc):\n",
    "        S.append(edge)\n",
    "\n",
    "    tau, tau_loc = TriestBase().updateCounters('insert', t, edge, S, M, tau, tau_loc)\n",
    "    \n",
    "        \n",
    "# Epsilon\n",
    "print(t)\n",
    "eps = max(1, ((t*(t-1)*(t-2))/(M*(M-1)*(M-2))))\n",
    "est_triangles = eps*tau\n",
    "print(\"Tau: \", tau)\n",
    "#print(\"Tau_loc: \", tau_loc)\n",
    "print(\"Eps: \", eps)\n",
    "print(\"Estimated triangles: \", est_triangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1669145064318,
     "user": {
      "displayName": "Tommaso Praturlon",
      "userId": "14876307488286215212"
     },
     "user_tz": -60
    },
    "id": "S2F_AwI2i7Q_",
    "outputId": "bdcf0770-93b3-485e-fbfb-a78673035ee4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncnt = Counter(C_1.values())\\nplt.bar(cnt.keys(), cnt.values())\\n\\nplt.xlabel('Frequency')\\nplt.ylabel('Number of documents with that frequency')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Graphs and statistics \n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "'''\n",
    "cnt = Counter(C_1.values())\n",
    "plt.bar(cnt.keys(), cnt.values())\n",
    "\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Number of documents with that frequency')\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
